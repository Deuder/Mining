{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getjobdescriptionsaslist(df):\n",
    "    \"\"\"\n",
    "    This Method puts all jobdescriptions of a df into one list of strings\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dateframe \n",
    "        The Job dataframe from which to take the descriptions from\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    descrstr : list\n",
    "        A List of strings filled with all job descriptions doc by doc\n",
    "    \"\"\"\n",
    "    #get all descriptions\n",
    "    descrstr = []\n",
    "    for i in range(len(df)):\n",
    "        newstr = removespecials(df.iloc[i,2].lower())\n",
    "        descrstr += [newstr]\n",
    "    return descrstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getjobdescriptions(df):\n",
    "    \"\"\"\n",
    "    This Method puts all jobdescriptions of a df into one string\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe          \n",
    "        The Job dataframe from which to take the descriptions from\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    string : descrstr\n",
    "        Wich is filled with all job descriptions at once\n",
    "    \"\"\"\n",
    "    #get all descriptions\n",
    "    descrstr = \"\"\n",
    "    for i in range(len(df)):\n",
    "        descrstr =descrstr +\" \"+ df.iloc[i,2]\n",
    "    return (removespecials(descrstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removespecials(str):\n",
    "    \"\"\"\n",
    "    This Method removes specialcaracters\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    str : string\n",
    "        The string from whom those specialcharacters shall be removed\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "         without those specialcaracters\n",
    "    \"\"\"\n",
    "    return str.replace(\"◾\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(vec, doc0, doc1):    \n",
    "    \"\"\"\n",
    "    This Method compares vector similarity within a term-document-matrix using cosine simularitys\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    vec : term-document-matrix\n",
    "    \n",
    "    doc0 : vector \n",
    "        Documentvector\n",
    "    doc1 : vector \n",
    "        Documentvector\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sim : {'0','1'} \n",
    "      a value between 0 and 1, whereas 0 means no similarity and 1 means equality\n",
    "    \"\"\"\n",
    "    #Ähnlichkeiten zwischen 2 Dokumenten\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    vec1 = np.array(vec[doc0].toarray())\n",
    "    vec2 = np.array(vec[doc1].toarray())\n",
    "    sim = (cosine_similarity(vec1, vec2))\n",
    "    return sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttm(vector):  \n",
    "    \"\"\"\n",
    "    This Method builds a term-term matrix \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vector : matrix\n",
    "    term-document-matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    term-term-matrix\n",
    "    \"\"\"\n",
    "    #similaritys between terms in a matrix\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    vec = vector.toarray()\n",
    "    vec = vec.transpose()\n",
    "    \n",
    "    #the Terms axis is 0\n",
    "    dim0 = vec.shape[0]\n",
    "    termtermmat = np.empty([dim0,dim0]) \n",
    "\n",
    "    for x in range(dim0):\n",
    "        for y in range(dim0):\n",
    "            termtermmat[x,y]= cosine_similarity([vec[x]],[vec[y]])\n",
    "\n",
    "    return termtermmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttm(vector):\n",
    "    \"\"\"\n",
    "    This Method builds a term-term matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vector : term-document-matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    term-term-matrix\n",
    "    \"\"\"\n",
    "    #similaritys between terms in a matrix\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    vec = vector.toarray()\n",
    "    vec = vec.transpose()\n",
    "    \n",
    "    #the Terms axis is 0\n",
    "    dim0 = vec.shape[0]\n",
    "    termtermmat = np.empty([dim0,dim0]) \n",
    "\n",
    "    for x in range(dim0):\n",
    "        for y in range(dim0):\n",
    "            termtermmat[x,y]= cosine_similarity([vec[x]],[vec[y]])\n",
    "\n",
    "    return termtermmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttm(vector):\n",
    "    \"\"\"\n",
    "    This Method builds a term-term matrix \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vector : term-document-matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    term-term-matrix\n",
    "    \"\"\"\n",
    "    #similaritys between terms in a matrix\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    vec = vector.toarray()\n",
    "    vec = vec.transpose()\n",
    "    \n",
    "    #the Terms axis is 0\n",
    "    dim0 = vec.shape[0]\n",
    "    termtermmat = np.empty([dim0,dim0]) \n",
    "\n",
    "    for x in range(dim0):\n",
    "        for y in range(dim0):\n",
    "            termtermmat[x,y]= cosine_similarity([vec[x]],[vec[y]])\n",
    "\n",
    "    return termtermmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getterms(df):\n",
    "    \"\"\"\n",
    "    This Method gets all terms out of a dataframe and returns them as a string list\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "        The dataframe from which the terms shall be selected\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    terms : stringlist\n",
    "        With all terms of that dataframe\n",
    "    \"\"\"\n",
    "    terms = []\n",
    "    for i in range(len(df)):\n",
    "        terms += [df.iloc[i,1].lower()]\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowhitespace(textlist):\n",
    "    \"\"\"\n",
    "    This Method eliminates all whitespaces out of a textlist\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    textlist : list\n",
    "        List with strings with too many whitespaces\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    textlist : list \n",
    "        Stringlist without whitespaces within those string\n",
    "    \"\"\"\n",
    "    for i in range(len(textlist)):\n",
    "        textlist[i] = textlist[i].replace(\" \", \"\")\n",
    "    return textlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacespace(docs, termsorg,terms):\n",
    "    \"\"\"\n",
    "    This Method replaces terms with spaces with terms without spaces and vice versa\n",
    "    (Needed, to count compound propernuns as one noun)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docs : list\n",
    "        Document list /string list\n",
    "    termsorg : stringlist \n",
    "        Terms in ther original form\n",
    "    terms : Stringlist\n",
    "        Terms in the form the originals shall be replaced\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    docs : list\n",
    "        documentlist with switched up terms\n",
    "    \"\"\"\n",
    "    for i in range(len(docs)):\n",
    "        for t in range(len(terms)):\n",
    "            docs[i] = docs[i].replace(termsorg[t].lower(), terms[t].lower())\n",
    "            #print(i, termsorg[t].lower(),terms[t].lower() )\n",
    "    return(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nounsde = r\"C:\\Users\\thegy\\Documents\\Studium\\HS FL 4\\Mining\\DFs\\nouns_de.csv\"\n",
    "nounsen = r\"C:\\Users\\thegy\\Documents\\Studium\\HS FL 4\\Mining\\DFs\\nouns_en.csv\"\n",
    "jobdf = r\"C:\\Users\\thegy\\Documents\\Studium\\HS FL 4\\Mining\\DFs\\jobdf.csv\"\n",
    "\n",
    "nounsde= pd.read_csv(nounsde, delimiter = \";\", decimal=\",\")\n",
    "nounsen = pd.read_csv(nounsen, delimiter = \";\", decimal=\",\")\n",
    "jobdf = pd.read_csv(jobdf, delimiter = \";\", decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get nterms of dataframe with proper nouns\n",
    "Compile them into term-document-matrixes\n",
    "Compare Docs similaritys with cosine simularity\n",
    "Create Term-Term-Matrix with term simularitys\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "df = nounsde\n",
    "nterms = 20\n",
    "\n",
    "\n",
    "#ged rid of those whitespaces between compound nouns, because otherwise those compound nouns would have been counted as 2 single words\n",
    "termsorg = getterms(df[:nterms])\n",
    "terms = nowhitespace(termsorg.copy())\n",
    "\n",
    "#print(termsorg)\n",
    "#print(terms)\n",
    "\n",
    "docs = getjobdescriptionsaslist(jobdf)\n",
    "\n",
    "#get rid of whitespaces in those terms within the docs\n",
    "docs = replacespace(docs, termsorg,terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 3 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(400, 20)\n"
     ]
    }
   ],
   "source": [
    "#get Count-Vectorizer - Term-Document-Matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvectorizer = CountVectorizer()\n",
    "cvectorizer.fit(terms)\n",
    "cvocab = cvectorizer.vocabulary_\n",
    "cvec = cvectorizer.transform(docs)\n",
    "\n",
    "#get Tfidf-Vectorizer - Term-Document-Matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvectorizer = TfidfVectorizer()\n",
    "tvectorizer.fit(terms)\n",
    "tvocab = tvectorizer.vocabulary_\n",
    "tvec = tvectorizer.transform(docs)\n",
    "\n",
    "print(cvec.toarray())\n",
    "print(cvec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]] [[0.]]\n"
     ]
    }
   ],
   "source": [
    "#compare docs\n",
    "doc0 = 1\n",
    "doc1 = 7\n",
    "sim0 = cossim(cvec,doc0,doc1)\n",
    "sim1 = cossim(tvec,doc0,doc1)\n",
    "print(sim0,sim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare terms in a term-term-matrix (own build)\n",
    "tttm = ttm(tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       analytics  big data  business intelligence  bwl  \\\n",
      "analytics               1.000000  0.153324               0.227709  0.0   \n",
      "big data                0.153324  1.000000               0.067555  0.0   \n",
      "business intelligence   0.227709  0.067555               1.000000  0.0   \n",
      "bwl                     0.000000  0.000000               0.000000  0.0   \n",
      "data analytics          0.213415  0.047578               0.134810  0.0   \n",
      "data engineering        0.119023  0.158272               0.078090  0.0   \n",
      "data mining             0.104023  0.191655               0.026038  0.0   \n",
      "data science            0.287374  0.120292               0.074423  0.0   \n",
      "data warehouse          0.123998  0.109431               0.117368  0.0   \n",
      "deep learning           0.076501  0.163434               0.007456  0.0   \n",
      "java                    0.110687  0.318698               0.045360  0.0   \n",
      "ki                      0.000000  0.000000               0.000000  0.0   \n",
      "machine learning        0.239248  0.207320               0.073933  0.0   \n",
      "nosql                   0.051986  0.219215               0.017252  0.0   \n",
      "python                  0.368956  0.304427               0.185778  0.0   \n",
      "sap                     0.073421  0.007858               0.039997  0.0   \n",
      "scala                   0.096807  0.346189               0.038031  0.0   \n",
      "spark                   0.150761  0.391284               0.115831  0.0   \n",
      "sql                     0.365824  0.206391               0.193298  0.0   \n",
      "use cases               0.071803  0.000000               0.000000  0.0   \n",
      "\n",
      "                       data analytics  data engineering  data mining  \\\n",
      "analytics                    0.213415          0.119023     0.104023   \n",
      "big data                     0.047578          0.158272     0.191655   \n",
      "business intelligence        0.134810          0.078090     0.026038   \n",
      "bwl                          0.000000          0.000000     0.000000   \n",
      "data analytics               1.000000          0.063854     0.055233   \n",
      "data engineering             0.063854          1.000000     0.056768   \n",
      "data mining                  0.055233          0.056768     1.000000   \n",
      "data science                 0.083184          0.176536     0.126140   \n",
      "data warehouse               0.089215          0.123613     0.013344   \n",
      "deep learning                0.000000          0.039414     0.163302   \n",
      "java                         0.047395          0.113838     0.141604   \n",
      "ki                           0.000000          0.000000     0.000000   \n",
      "machine learning             0.074731          0.110601     0.311899   \n",
      "nosql                        0.006547          0.215334     0.091768   \n",
      "python                       0.179223          0.285645     0.212165   \n",
      "sap                          0.025779          0.000000     0.021993   \n",
      "scala                        0.022391          0.153975     0.108584   \n",
      "spark                        0.027670          0.254008     0.105025   \n",
      "sql                          0.231286          0.228709     0.181069   \n",
      "use cases                    0.097513          0.044399     0.017922   \n",
      "\n",
      "                       data science  data warehouse  deep learning      java  \\\n",
      "analytics                  0.287374        0.123998       0.076501  0.110687   \n",
      "big data                   0.120292        0.109431       0.163434  0.318698   \n",
      "business intelligence      0.074423        0.117368       0.007456  0.045360   \n",
      "bwl                        0.000000        0.000000       0.000000  0.000000   \n",
      "data analytics             0.083184        0.089215       0.000000  0.047395   \n",
      "data engineering           0.176536        0.123613       0.039414  0.113838   \n",
      "data mining                0.126140        0.013344       0.163302  0.141604   \n",
      "data science               1.000000        0.056032       0.085885  0.097026   \n",
      "data warehouse             0.056032        1.000000       0.015733  0.018850   \n",
      "deep learning              0.085885        0.015733       1.000000  0.095272   \n",
      "java                       0.097026        0.018850       0.095272  1.000000   \n",
      "ki                         0.000000        0.000000       0.000000  0.000000   \n",
      "machine learning           0.418708        0.038880       0.376479  0.239585   \n",
      "nosql                      0.082750        0.013037       0.029116  0.130543   \n",
      "python                     0.314894        0.220820       0.164035  0.332197   \n",
      "sap                        0.054685        0.000000       0.000000  0.007631   \n",
      "scala                      0.124123        0.030506       0.143976  0.471970   \n",
      "spark                      0.167902        0.120776       0.058916  0.274832   \n",
      "sql                        0.175060        0.296931       0.055949  0.194400   \n",
      "use cases                  0.109923        0.033524       0.080472  0.029181   \n",
      "\n",
      "                        ki  machine learning     nosql    python       sap  \\\n",
      "analytics              0.0          0.239248  0.051986  0.368956  0.073421   \n",
      "big data               0.0          0.207320  0.219215  0.304427  0.007858   \n",
      "business intelligence  0.0          0.073933  0.017252  0.185778  0.039997   \n",
      "bwl                    0.0          0.000000  0.000000  0.000000  0.000000   \n",
      "data analytics         0.0          0.074731  0.006547  0.179223  0.025779   \n",
      "data engineering       0.0          0.110601  0.215334  0.285645  0.000000   \n",
      "data mining            0.0          0.311899  0.091768  0.212165  0.021993   \n",
      "data science           0.0          0.418708  0.082750  0.314894  0.054685   \n",
      "data warehouse         0.0          0.038880  0.013037  0.220820  0.000000   \n",
      "deep learning          0.0          0.376479  0.029116  0.164035  0.000000   \n",
      "java                   0.0          0.239585  0.130543  0.332197  0.007631   \n",
      "ki                     0.0          0.000000  0.000000  0.000000  0.000000   \n",
      "machine learning       0.0          1.000000  0.162802  0.381626  0.011360   \n",
      "nosql                  0.0          0.162802  1.000000  0.203127  0.000000   \n",
      "python                 0.0          0.381626  0.203127  1.000000  0.006954   \n",
      "sap                    0.0          0.011360  0.000000  0.006954  1.000000   \n",
      "scala                  0.0          0.166101  0.179005  0.241317  0.000000   \n",
      "spark                  0.0          0.188310  0.131548  0.342645  0.000000   \n",
      "sql                    0.0          0.212452  0.153793  0.585999  0.018181   \n",
      "use cases              0.0          0.095716  0.000000  0.062775  0.000000   \n",
      "\n",
      "                          scala     spark       sql  use cases  \n",
      "analytics              0.096807  0.150761  0.365824   0.071803  \n",
      "big data               0.346189  0.391284  0.206391   0.000000  \n",
      "business intelligence  0.038031  0.115831  0.193298   0.000000  \n",
      "bwl                    0.000000  0.000000  0.000000   0.000000  \n",
      "data analytics         0.022391  0.027670  0.231286   0.097513  \n",
      "data engineering       0.153975  0.254008  0.228709   0.044399  \n",
      "data mining            0.108584  0.105025  0.181069   0.017922  \n",
      "data science           0.124123  0.167902  0.175060   0.109923  \n",
      "data warehouse         0.030506  0.120776  0.296931   0.033524  \n",
      "deep learning          0.143976  0.058916  0.055949   0.080472  \n",
      "java                   0.471970  0.274832  0.194400   0.029181  \n",
      "ki                     0.000000  0.000000  0.000000   0.000000  \n",
      "machine learning       0.166101  0.188310  0.212452   0.095716  \n",
      "nosql                  0.179005  0.131548  0.153793   0.000000  \n",
      "python                 0.241317  0.342645  0.585999   0.062775  \n",
      "sap                    0.000000  0.000000  0.018181   0.000000  \n",
      "scala                  1.000000  0.351843  0.110771   0.021341  \n",
      "spark                  0.351843  1.000000  0.194716   0.012488  \n",
      "sql                    0.110771  0.194716  1.000000   0.068815  \n",
      "use cases              0.021341  0.012488  0.068815   1.000000  \n"
     ]
    }
   ],
   "source": [
    "#Allocate columns to terms\n",
    "name = tvectorizer.get_feature_names()\n",
    "name = replacespace(name, terms, termsorg)\n",
    "\n",
    "dfmat ={}\n",
    "for i in range(len(name)):\n",
    "    dfmat[name[i]]=tttm[i]\n",
    "\n",
    "ttdf = pd.DataFrame(dfmat, index = name)\n",
    "print(ttdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttdf.to_csv(r\"C:\\Users\\thegy\\Documents\\Studium\\HS FL 4\\Mining\\DFs\\ttm.csv\", sep=\";\",decimal=\",\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
