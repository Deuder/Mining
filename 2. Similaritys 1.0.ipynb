{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e05a5554-f31f-45d5-8c88-66bcd988c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getjobdescriptionsaslist(df):\n",
    "    \"\"\"\n",
    "    This Method puts all jobdescriptions of a df into one list of strings\n",
    "    @param df: The Job dataframe from which to take the descriptions from\n",
    "    @return: list of strings filled with all job descriptions doc by doc\n",
    "    \"\"\"\n",
    "    #get all descriptions\n",
    "    descrstr = []\n",
    "    for i in range(len(df)):\n",
    "        newstr = removespecials(df.iloc[i,2].lower())\n",
    "        descrstr += [newstr]\n",
    "    return descrstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "643e8ed2-f7d0-4566-b925-e906fa2bbde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getjobdescriptions(df):\n",
    "    \"\"\"\n",
    "    This Method puts all jobdescriptions of a df into one string\n",
    "    @param df: The Job dataframe from which to take the descriptions from\n",
    "    @return: string filled with all job descriptions at once\n",
    "    \"\"\"\n",
    "    #get all descriptions\n",
    "    descrstr = \"\"\n",
    "    for i in range(len(df)):\n",
    "        descrstr =descrstr +\" \"+ df.iloc[i,2]\n",
    "    return (removespecials(descrstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dd8f0d7a-433a-49bd-8459-19a148081e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removespecials(str):\n",
    "    \"\"\"\n",
    "    This Method removes specialcaracters\n",
    "    @param str: the string from whom those specialcharacters shall be removed\n",
    "    @return: string without those specialcaracters\n",
    "    \"\"\"\n",
    "    return str.replace(\"◾\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "34bdd978-5a17-4372-a873-d14b4d73d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This Method compares vector similarity within a term-document-matrix using cosine simularitys\n",
    "@param vec: term-document-matrix\n",
    "@param doc0: Documentvector\n",
    "@param doc1: Documentvector\n",
    "@return: a value between 0 and 1, whereas 0 means no similarity and 1 means equality\n",
    "\"\"\"\n",
    "def cossim(vec, doc0, doc1):    \n",
    "    #Ähnlichkeiten zwischen 2 Dokumenten\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    vec1 = np.array(vec[doc0].toarray())\n",
    "    vec2 = np.array(vec[doc1].toarray())\n",
    "    sim = (cosine_similarity(vec1, vec2))\n",
    "    return sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cc5f8d24-d6d7-481e-a110-413291ff72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This Method builds a term-term matrix \n",
    "@param vector: term-document-matrix\n",
    "@return: a term-term-matrix\n",
    "\"\"\"\n",
    "def ttm(vector):   \n",
    "    #similaritys between terms in a matrix\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    vec = vector.toarray()\n",
    "    vec = vec.transpose()\n",
    "    \n",
    "    #the Terms axis is 0\n",
    "    dim0 = vec.shape[0]\n",
    "    termtermmat = np.empty([dim0,dim0]) \n",
    "\n",
    "    for x in range(dim0):\n",
    "        for y in range(dim0):\n",
    "            termtermmat[x,y]= cosine_similarity([vec[x]],[vec[y]])\n",
    "\n",
    "    return termtermmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f9e24-4f26-4731-99d7-5f038582aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This Method builds a term-term matrix \n",
    "@param vector: term-document-matrix\n",
    "@return: a term-term-matrix\n",
    "\"\"\"\n",
    "def ttm(vector):   \n",
    "    #similaritys between terms in a matrix\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    vec = vector.toarray()\n",
    "    vec = vec.transpose()\n",
    "    \n",
    "    #the Terms axis is 0\n",
    "    dim0 = vec.shape[0]\n",
    "    termtermmat = np.empty([dim0,dim0]) \n",
    "\n",
    "    for x in range(dim0):\n",
    "        for y in range(dim0):\n",
    "            termtermmat[x,y]= cosine_similarity([vec[x]],[vec[y]])\n",
    "\n",
    "    return termtermmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e60582-5959-4209-a9a7-670405cebef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This Method builds a term-term matrix \n",
    "@param vector: term-document-matrix\n",
    "@return: a term-term-matrix\n",
    "\"\"\"\n",
    "def ttm(vector):   \n",
    "    #similaritys between terms in a matrix\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    vec = vector.toarray()\n",
    "    vec = vec.transpose()\n",
    "    \n",
    "    #the Terms axis is 0\n",
    "    dim0 = vec.shape[0]\n",
    "    termtermmat = np.empty([dim0,dim0]) \n",
    "\n",
    "    for x in range(dim0):\n",
    "        for y in range(dim0):\n",
    "            termtermmat[x,y]= cosine_similarity([vec[x]],[vec[y]])\n",
    "\n",
    "    return termtermmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f3edcae9-b198-45b4-8ed5-2327c68f60cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This Method gets all terms out of a dataframe and returns them as a string list\n",
    "@param df: the dataframe from which the terms shall be selected\n",
    "@return: stringlist with all terms of that dataframe\n",
    "\"\"\"\n",
    "def getterms(df):\n",
    "    terms = []\n",
    "    for i in range(len(df)):\n",
    "        terms += [df.iloc[i,1].lower()]\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "64f62100-138b-43e8-b2f5-cc413d0eb38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This Method eliminates all whitespaces out of a textlist\n",
    "@param textlist: tlist with strings with too many whitespaces\n",
    "@return: stringlist without whitespaces within those string\n",
    "\"\"\"\n",
    "def nowhitespace(textlist):\n",
    "    for i in range(len(textlist)):\n",
    "        textlist[i] = textlist[i].replace(\" \", \"\")\n",
    "    return textlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "85b3e2f3-2acd-4122-8f73-011e8fe95be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This Method replaces terms with spaces with terms without spaces and vice versa\n",
    "(Needed, to count compound propernuns as one noun)\n",
    "@param docs: document list /string list)\n",
    "@param termsorg: (stringlist) terms in ther original form\n",
    "@param terms: (stringlist) terms in the form the originals shall be replaced\n",
    "@return: documentlist with switched up terms\n",
    "\"\"\"\n",
    "def replacespace(docs, termsorg,terms):\n",
    "    for i in range(len(docs)):\n",
    "        for t in range(len(terms)):\n",
    "            docs[i] = docs[i].replace(termsorg[t].lower(), terms[t].lower())\n",
    "            #print(i, termsorg[t].lower(),terms[t].lower() )\n",
    "    return(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e2090f51-ed05-4f35-94aa-a069946e25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nounsde = r\"C:\\Users\\thegy\\Documents\\Studium\\HS FL 4\\Mining\\DFs\\nouns_de.csv\"\n",
    "nounsen = r\"C:\\Users\\thegy\\Documents\\Studium\\HS FL 4\\Mining\\DFs\\nouns_en.csv\"\n",
    "jobdf = r\"C:\\Users\\thegy\\Documents\\Studium\\HS FL 4\\Mining\\DFs\\jobdf.csv\"\n",
    "\n",
    "nounsde= pd.read_csv(nounsde, delimiter = \";\", decimal=\",\")\n",
    "nounsen = pd.read_csv(nounsen, delimiter = \";\", decimal=\",\")\n",
    "jobdf = pd.read_csv(jobdf, delimiter = \";\", decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "07fda105-e14f-45a6-9f81-f5773a86520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get nterms of dataframe with proper nouns\n",
    "Compile them into term-document-matrixes\n",
    "Compare Docs similaritys with cosine simularity\n",
    "Create Term-Term-Matrix with term simularitys\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "df = nounsde\n",
    "nterms = 20\n",
    "\n",
    "\n",
    "#ged rid of those whitespaces between compound nouns, because otherwise those compound nouns would have been counted as 2 single words\n",
    "termsorg = getterms(df[:nterms])\n",
    "terms = nowhitespace(termsorg.copy())\n",
    "\n",
    "#print(termsorg)\n",
    "#print(terms)\n",
    "\n",
    "docs = getjobdescriptionsaslist(jobdf)\n",
    "\n",
    "#get rid of whitespaces in those terms within the docs\n",
    "docs = replacespace(docs, termsorg,terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e79cff85-0155-42a3-b988-0235fddedf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 3 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(400, 20)\n"
     ]
    }
   ],
   "source": [
    "#get Count-Vectorizer - Term-Document-Matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvectorizer = CountVectorizer()\n",
    "cvectorizer.fit(terms)\n",
    "cvocab = cvectorizer.vocabulary_\n",
    "cvec = cvectorizer.transform(docs)\n",
    "\n",
    "#get Tfidf-Vectorizer - Term-Document-Matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvectorizer = TfidfVectorizer()\n",
    "tvectorizer.fit(terms)\n",
    "tvocab = tvectorizer.vocabulary_\n",
    "tvec = tvectorizer.transform(docs)\n",
    "\n",
    "print(cvec.toarray())\n",
    "print(cvec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "577db660-9963-4e8e-a321-a89347e75fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]] [[0.]]\n"
     ]
    }
   ],
   "source": [
    "#compare docs\n",
    "doc0 = 1\n",
    "doc1 = 7\n",
    "sim0 = cossim(cvec,doc0,doc1)\n",
    "sim1 = cossim(tvec,doc0,doc1)\n",
    "print(sim0,sim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "eb4f01a5-8b28-4e68-9e8f-c6b01ef351fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare terms in a term-term-matrix (own build)\n",
    "tttm = ttm(tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cff6a8f9-923a-47f0-be39-6e575ab0e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       analytics  big data  business intelligence  bwl  \\\n",
      "analytics               1.000000  0.153324               0.227709  0.0   \n",
      "big data                0.153324  1.000000               0.067555  0.0   \n",
      "business intelligence   0.227709  0.067555               1.000000  0.0   \n",
      "bwl                     0.000000  0.000000               0.000000  0.0   \n",
      "data analytics          0.213415  0.047578               0.134810  0.0   \n",
      "data engineering        0.119023  0.158272               0.078090  0.0   \n",
      "data mining             0.104023  0.191655               0.026038  0.0   \n",
      "data science            0.287374  0.120292               0.074423  0.0   \n",
      "data warehouse          0.123998  0.109431               0.117368  0.0   \n",
      "deep learning           0.076501  0.163434               0.007456  0.0   \n",
      "java                    0.110687  0.318698               0.045360  0.0   \n",
      "ki                      0.000000  0.000000               0.000000  0.0   \n",
      "machine learning        0.239248  0.207320               0.073933  0.0   \n",
      "nosql                   0.051986  0.219215               0.017252  0.0   \n",
      "python                  0.368956  0.304427               0.185778  0.0   \n",
      "sap                     0.073421  0.007858               0.039997  0.0   \n",
      "scala                   0.096807  0.346189               0.038031  0.0   \n",
      "spark                   0.150761  0.391284               0.115831  0.0   \n",
      "sql                     0.365824  0.206391               0.193298  0.0   \n",
      "use cases               0.071803  0.000000               0.000000  0.0   \n",
      "\n",
      "                       data analytics  data engineering  data mining  \\\n",
      "analytics                    0.213415          0.119023     0.104023   \n",
      "big data                     0.047578          0.158272     0.191655   \n",
      "business intelligence        0.134810          0.078090     0.026038   \n",
      "bwl                          0.000000          0.000000     0.000000   \n",
      "data analytics               1.000000          0.063854     0.055233   \n",
      "data engineering             0.063854          1.000000     0.056768   \n",
      "data mining                  0.055233          0.056768     1.000000   \n",
      "data science                 0.083184          0.176536     0.126140   \n",
      "data warehouse               0.089215          0.123613     0.013344   \n",
      "deep learning                0.000000          0.039414     0.163302   \n",
      "java                         0.047395          0.113838     0.141604   \n",
      "ki                           0.000000          0.000000     0.000000   \n",
      "machine learning             0.074731          0.110601     0.311899   \n",
      "nosql                        0.006547          0.215334     0.091768   \n",
      "python                       0.179223          0.285645     0.212165   \n",
      "sap                          0.025779          0.000000     0.021993   \n",
      "scala                        0.022391          0.153975     0.108584   \n",
      "spark                        0.027670          0.254008     0.105025   \n",
      "sql                          0.231286          0.228709     0.181069   \n",
      "use cases                    0.097513          0.044399     0.017922   \n",
      "\n",
      "                       data science  data warehouse  deep learning      java  \\\n",
      "analytics                  0.287374        0.123998       0.076501  0.110687   \n",
      "big data                   0.120292        0.109431       0.163434  0.318698   \n",
      "business intelligence      0.074423        0.117368       0.007456  0.045360   \n",
      "bwl                        0.000000        0.000000       0.000000  0.000000   \n",
      "data analytics             0.083184        0.089215       0.000000  0.047395   \n",
      "data engineering           0.176536        0.123613       0.039414  0.113838   \n",
      "data mining                0.126140        0.013344       0.163302  0.141604   \n",
      "data science               1.000000        0.056032       0.085885  0.097026   \n",
      "data warehouse             0.056032        1.000000       0.015733  0.018850   \n",
      "deep learning              0.085885        0.015733       1.000000  0.095272   \n",
      "java                       0.097026        0.018850       0.095272  1.000000   \n",
      "ki                         0.000000        0.000000       0.000000  0.000000   \n",
      "machine learning           0.418708        0.038880       0.376479  0.239585   \n",
      "nosql                      0.082750        0.013037       0.029116  0.130543   \n",
      "python                     0.314894        0.220820       0.164035  0.332197   \n",
      "sap                        0.054685        0.000000       0.000000  0.007631   \n",
      "scala                      0.124123        0.030506       0.143976  0.471970   \n",
      "spark                      0.167902        0.120776       0.058916  0.274832   \n",
      "sql                        0.175060        0.296931       0.055949  0.194400   \n",
      "use cases                  0.109923        0.033524       0.080472  0.029181   \n",
      "\n",
      "                        ki  machine learning     nosql    python       sap  \\\n",
      "analytics              0.0          0.239248  0.051986  0.368956  0.073421   \n",
      "big data               0.0          0.207320  0.219215  0.304427  0.007858   \n",
      "business intelligence  0.0          0.073933  0.017252  0.185778  0.039997   \n",
      "bwl                    0.0          0.000000  0.000000  0.000000  0.000000   \n",
      "data analytics         0.0          0.074731  0.006547  0.179223  0.025779   \n",
      "data engineering       0.0          0.110601  0.215334  0.285645  0.000000   \n",
      "data mining            0.0          0.311899  0.091768  0.212165  0.021993   \n",
      "data science           0.0          0.418708  0.082750  0.314894  0.054685   \n",
      "data warehouse         0.0          0.038880  0.013037  0.220820  0.000000   \n",
      "deep learning          0.0          0.376479  0.029116  0.164035  0.000000   \n",
      "java                   0.0          0.239585  0.130543  0.332197  0.007631   \n",
      "ki                     0.0          0.000000  0.000000  0.000000  0.000000   \n",
      "machine learning       0.0          1.000000  0.162802  0.381626  0.011360   \n",
      "nosql                  0.0          0.162802  1.000000  0.203127  0.000000   \n",
      "python                 0.0          0.381626  0.203127  1.000000  0.006954   \n",
      "sap                    0.0          0.011360  0.000000  0.006954  1.000000   \n",
      "scala                  0.0          0.166101  0.179005  0.241317  0.000000   \n",
      "spark                  0.0          0.188310  0.131548  0.342645  0.000000   \n",
      "sql                    0.0          0.212452  0.153793  0.585999  0.018181   \n",
      "use cases              0.0          0.095716  0.000000  0.062775  0.000000   \n",
      "\n",
      "                          scala     spark       sql  use cases  \n",
      "analytics              0.096807  0.150761  0.365824   0.071803  \n",
      "big data               0.346189  0.391284  0.206391   0.000000  \n",
      "business intelligence  0.038031  0.115831  0.193298   0.000000  \n",
      "bwl                    0.000000  0.000000  0.000000   0.000000  \n",
      "data analytics         0.022391  0.027670  0.231286   0.097513  \n",
      "data engineering       0.153975  0.254008  0.228709   0.044399  \n",
      "data mining            0.108584  0.105025  0.181069   0.017922  \n",
      "data science           0.124123  0.167902  0.175060   0.109923  \n",
      "data warehouse         0.030506  0.120776  0.296931   0.033524  \n",
      "deep learning          0.143976  0.058916  0.055949   0.080472  \n",
      "java                   0.471970  0.274832  0.194400   0.029181  \n",
      "ki                     0.000000  0.000000  0.000000   0.000000  \n",
      "machine learning       0.166101  0.188310  0.212452   0.095716  \n",
      "nosql                  0.179005  0.131548  0.153793   0.000000  \n",
      "python                 0.241317  0.342645  0.585999   0.062775  \n",
      "sap                    0.000000  0.000000  0.018181   0.000000  \n",
      "scala                  1.000000  0.351843  0.110771   0.021341  \n",
      "spark                  0.351843  1.000000  0.194716   0.012488  \n",
      "sql                    0.110771  0.194716  1.000000   0.068815  \n",
      "use cases              0.021341  0.012488  0.068815   1.000000  \n"
     ]
    }
   ],
   "source": [
    "#Allocate columns to terms\n",
    "name = tvectorizer.get_feature_names()\n",
    "name = replacespace(name, terms, termsorg)\n",
    "\n",
    "dfmat ={}\n",
    "for i in range(len(name)):\n",
    "    dfmat[name[i]]=tttm[i]\n",
    "\n",
    "ttdf = pd.DataFrame(dfmat, index = name)\n",
    "print(ttdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5b9a78cd-7172-4e39-aa58-1664746a34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttdf.to_csv(r\"C:\\Users\\thegy\\Documents\\Studium\\HS FL 4\\Mining\\DFs\\ttm.csv\", sep=\";\",decimal=\",\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1c585774-f3f8-490d-be29-58bffa401efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import numpy as np\n",
    "\n",
    "df = nounsde\n",
    "nterms = 20\n",
    "\n",
    "termsorg = getterms(df[:nterms])\n",
    "terms = nowhitespace(termsorg.copy())\n",
    "\n",
    "docs = getjobdescriptions(jobdf)\n",
    "\n",
    "from spacy.lang.de import German\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "#from spacy.lang.en import English\n",
    "#nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "nlp.max_length = 2000000\n",
    "doc = nlp(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "97587686-cb47-4179-a946-e24099aaabbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (96,) into shape (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-168-fc5216737249>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mvec_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (96,) into shape (0,)"
     ]
    }
   ],
   "source": [
    "vec_arr = np.empty((len(docs), nlp.vocab.vectors_length))\n",
    "for i in range(len(docs)):\n",
    "    txt = docs[i]\n",
    "    doc = nlp(txt)\n",
    "    vec_arr[i] = doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eeb56d-baa4-43b2-99f3-68a33dd30adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7995ad4-504b-4bfe-b966-2cab8a86bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlp.vocab.vectors_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e56e0c-425a-45fa-a855-96fdec59e9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
